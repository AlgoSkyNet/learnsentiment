---
title: "R Notebook"
output: html_notebook
---

## Chapter 3 Visualization

Is your property a good rental? What do people look for in a good rental?

### Step 1: What do you want to know?

Throughout this chapter you will analyse the text of a corpus of Airbnb housing rental reviews. Which of the following questions can you answer using a sentiment analysis of these reviews?

ANSWER THE QUESTION
50XP
Possible Answers
What document clusters exist in the reviews?
press 1
How many words are associated with rental reviews?
press 2
--> correct: What property qualities are listed in positive or negative comments?
press 3
What named entities are in the documents?



### Step 2: Identify Text Sources

In this short exercise you will load and examine a small corpus of property rental reviews from around Boston. Hopefully you already know read.csv() which enables you to load a comma separated file. In this exercise you will also need to specify stringsAsFactors = FALSE when loading the corpus. This ensures the reviews are character classes, not factors. This may seem mundane but the point of this chapter is to get you doing an entire workflow from start to finish so let's begin with data ingestion!

Next you simply apply str() to review the data frame's structure. It is a convenient function for compactly displaying initial values and class types for vectors.

Lastly you will apply dim() to print the dimensions of the data frame. For a data frame, your console will print the number of rows and the number of columns.

Other functions like head(), tail() or summary() are often used for data exploration but in this case we keep the examination short so you can get to the fun sentiment analysis!

INSTRUCTIONS
100XP
INSTRUCTIONS
100XP
The Boston property rental reviews are stored in a CSV file located by the predefined variable bos_reviews_file.

Load the property reviews from bos_reviews_file with read.csv(). Call the object bos_reviews. Be sure to pass in the parameter stringsAsFactors = FALSE so the comments are not unique factors.
Examine the structure of the data frame using the base str() function applied to bos_reviews.
Find out how many reviews you are working with by calling dim() on the bos_reviews.




```{r}
# bos_reviews_file has been pre-defined
bos_reviews_file

# load raw text
bos_reviews <- read.csv(bos_reviews_file, stringsAsFactors = FALSE)

# Structure
str(bos_reviews)

# Dimensions
dim(bos_reviews)
```
> bos_reviews_file
[1] "/usr/local/share/datasets/bos_reviews.csv"

> str(bos_reviews)
'data.frame':	1000 obs. of  2 variables:
 $ id      : int  1 2 3 4 5 6 7 8 9 10 ...
 $ comments: chr  "My daughter and I had a wonderful stay with Maura. She kept in close touch with us throughout the day as we wer"| __truncated__ "We stay at Elizabeth's place for 3 nights in October 2014.\nThe apartment is really a great place to stay. \nLo"| __truncated__ "If you're staying in South Boston, this is a terrific place to camp out. The apartment and bedroom are lovely, "| __truncated__ "Derian and Brian were great and prompt with their communications with us. The room was as described; it was a s"| __truncated__ ...
> 
> # Dimensions
> dim(bos_reviews)
[1] 1000    2


### Quickly examine the basic polarity

When starting a sentiment project, sometimes a quick polarity() will help you set expectations or learn about the problem. In this exercise (to save time), you will apply polarity() to a portion of the comments vector while the larger polarity object is loaded in the background.

Using a kernel density plot you should notice the reviews do not center on 0. Often there are two causes for this sentiment "grade inflation." First, social norms may lead respondents to be pleasant instead of neutral. This, of course, is channel specific. Particularly snarky channels like e-sports or social media posts may skew negative leading to "deflation." These channels have different expectations. A second possible reason could be "feature based sentiment". In some reviews an author may write "the bed was comfortable and nice but the kitchen was dirty and gross." The sentiment of this type of review encompasses multiple features simultaneously and therefore could make an average score skewed.

In a subsequent exercise you will adjust this "grade inflation" but here explore the reviews without any change.

INSTRUCTIONS
100XP
INSTRUCTIONS
100XP
Create practice_pol using polarity() on the first six reviews as in bos_reviews$comments[1:6]
Review the returned polarity object by calling practice_pol.
Call summary() on practice_pol$all$polarity - this will access the overall polarity for all 6 comments.
We've also loaded a larger polarity object for all 1000 comments. This new object is called bos_pol. Now apply summary() to the correct list element that returns all polarity scores of bos_pol.
The sample code has a barplot and kernel density plot almost ready to print. However, you must enter the data frame representing all scores. Hint: in the previous step, polarity represents a column of this data frame.

```{r}
# Practice apply polarity to first 6 reviews
practice_pol <- polarity(bos_reviews$comments[1:6])

# Review the object
practice_pol

# Check out the practice polarity
summary(practice_pol$all$polarity)

# Summary for all reviews
summary(bos_pol$all$polarity)

# Plot it
ggplot(bos_pol$all, aes(x = polarity, y = ..density..)) +
  theme_gdocs() + 
  geom_histogram(binwidth = 0.25, fill = "#bada55", colour = "grey60") +
  geom_density(size = 0.75)
```

[resulted plot]("download (12).png")



### Create a Polarity Based Corpora

In this exercise you will perform Step 3 of the text mining workflow. Although qdap isn't a tidy package you will mutate() a new column based on the returned polarity list representing all polarity (that's a hint BTW) scores. In chapter 3 we used a custom function pol_subsections which uses only base R declarations. However, in following the tidy principles this exercise uses filter() then introduces pull(). The pull() function works like works like [[ to extract a single variable.

Once segregated you collapse all the positive and negative comments into two larger documents representing all words among the positive and negative rental reviews.

Lastly, you will create a Term Frequency Inverse Document Frequency (TFIDF) weighted Term Document Matrix (TDM). Since this exercise code starts with a tidy structure, some of the functions borrowed from tm are used along with the %>% operator to keep the style consistent. If the basics of the tm package aren't familiar check out the Text Mining: Bag of Words course. Instead of counting the number of times a word is used (frequency), the values in the TDM are penalized for over used terms, which helps reduce non-informative words.

INSTRUCTIONS
100XP
INSTRUCTIONS
100XP
Review the polarity group with bos_pol$group. Note the average polarity scores are not centered at 0.
Forward bos_reviews to mutate() and create a new column polarity equal to bos_pol$all$polarity.
Forward bos_reviews_with_pol to filter() with polarity > 0 and then pull() the comments column. The new object, pos_comments, contains only positive comments.
Now create neg_comments following the previous workflow but change polarity < 0. Don't forget to pull() the comments column.
Using paste() with pos_comments and the additional parameter collapse = " " will collapse all the positive reviews into a single document.
Now make neg_terms as a single document again using paste() on neg_comments with collapse = " ".
Create all_terms by concatenating pos_terms and neg_terms
Forward all_terms to VectorSource() and VCorpus().
Pass all_corpus to TermDocumentMatrix() with control = list(weighting = weightTfIdf, removePunctuation = TRUE, stopwords = stopwords(kind = 'en'))).
Review the TDM by calling all_tdm.

```{r}
# Review
bos_pol$group

# Add polarity column
bos_reviews_with_pol <- bos_reviews %>%
  mutate(polarity = bos_pol$all$polarity)

# Subset positive comments 
pos_comments <- bos_reviews_with_pol %>%
  filter(polarity > 0) %>%
  pull(comments)

# Subset negative comments
neg_comments <- bos_reviews_with_pol %>%
  filter(polarity < 0) %>%
  pull(comments)

# Paste and collapse the positive comments
pos_terms <- paste(pos_comments, collapse = " ")

# Paste and collapse the negative comments
neg_terms <- paste(neg_comments, collapse = " ")

# Concatenate the terms
all_terms <- c(pos_terms, neg_terms)

# Pipe a VectorSource Corpus
all_corpus <- all_terms %>% 
  VectorSource() %>% 
  VCorpus()

# Simple TFIDF TDM
all_tdm <- TermDocumentMatrix(
  all_corpus, 
  control = list(
    weighting = weightTfIdf, 
    removePunctuation = TRUE, 
    stopwords = stopwords(kind = "en")
  )
)

# Examine the TDM
all_tdm
```

> bos_pol$group
  all total.sentences total.words ave.polarity sd.polarity stan.mean.polarity
1 all            1000       70481    0.9021735   0.5015318           1.798836

> all_tdm
<<TermDocumentMatrix (terms: 4969, documents: 2)>>
Non-/sparse entries: 4352/5586
Sparsity           : 56%
Maximal term length: 186
Weighting          : term frequency - inverse document frequency (normalized) (tf-idf)

### Create a Tidy Text Tibble!

Since you learned about tidy principles this code helps you organize your data into a tibble so you can then work within the tidyverse!

Previously you learned that applying tidy() on a TermDocumentMatrix() object will convert the TDM to a tibble. In this exercise you will create the word data directly from the review column called comments.

First you use unnest_tokens() to make the text lowercase and tokenize the reviews into single words.

Sometimes it is useful to capture the original word order within each group of a corpus. To do so, use mutate(). In mutate() you will use seq_along() to create a sequence of numbers from 1 to the length of the object. This will capture the word order as it was written.

In the tm package, you would use removeWords() to remove stopwords. In the tidyverse you first need to load the stop words lexicon and then apply an anti_join() between the tidy text data frame and the stopwords.

INSTRUCTIONS
100XP
INSTRUCTIONS
100XP
Create tidy_reviews by piping (%>%) the original reviews object bos_reviews to the unnest_tokens() function. Pass in a new column name, word and declare the comments column. Remember in the tidyverse you don't need a $ or quotes.
Create a new variable the tidy way! Rewrite tidy_reviews by piping tidy_reviews to group_by with the column id. Then %>% it again to mutate(). Within mutate create a new variable original_word_order equal to seq_along(word).
Print out the tibble, tidy_reviews.
Load the premade "SMART" stopwords to your R session with data("stop_words").
Overwrite tidy_reviews by passing the original tidy_reviews to anti_join() with a %>%. Within anti_join() pass in the predetermined stop_words lexicon.

```{r}
# Vector to tibble
tidy_reviews <- bos_reviews %>% 
  unnest_tokens(word, comments)

# Group by and mutate
tidy_reviews <- tidy_reviews %>% 
  group_by(id) %>% 
  mutate(original_word_order = seq_along(word))

# Quick review
tidy_reviews

# Load stopwords
data("stop_words")

# Perform anti-join
tidy_reviews_without_stopwords <- tidy_reviews %>% 
  anti_join(stop_words)
```






### Compare Tidy Sentiment to Qdap Polarity

Here you will learn that differing sentiment methods will cause different results. Often you will simply need to have results align directionally although the specifics may be different. In the last exercise you created tidy_reviews which is a data frame of rental reviews without stopwords. Earlier in the chapter, you calculated and plotted qdap's basic polarity() function. This showed you the reviews tend to be positive.

Now let's perform a similar analysis the tidytext way! Recall from an earlier chapter you will perform an inner_join() followed by count() and then a spread().

Lastly, you will create a new column using mutate() and passing in positive - negative.

INSTRUCTIONS
100XP
Using the get_sentiments() function with "bing" will automatically filter the tidytext sentiments data. Call the lexicon bing.
Since you already wrote this code in Chapter 2 simply enter in the lexicon object, bing, the new column name (polarity) and its calculation within mutate().
Lastly call summary() on the new object pos_neg. Although the values are different, are most rental reviews similarly positive compared to using polarity()? Do you see "grade inflation?"





```{r}
# Get the correct lexicon
bing <- get_sentiments("bing")

# Calculate polarity for each review
pos_neg <- tidy_reviews %>% 
  inner_join(bing) %>%
  count(sentiment) %>%
  spread(sentiment, n, fill = 0) %>% 
  mutate(polarity = positive - negative)

# Check outcome
summary(pos_neg)
```

> # Check outcome
> summary(pos_neg)
       id            negative          positive        polarity      
 Min.   :   1.0   Min.   : 0.0000   Min.   : 0.00   Min.   :-11.000  
 1st Qu.: 253.0   1st Qu.: 0.0000   1st Qu.: 3.00   1st Qu.:  2.000  
 Median : 498.0   Median : 0.0000   Median : 4.00   Median :  4.000  
 Mean   : 500.4   Mean   : 0.6139   Mean   : 4.97   Mean   :  4.356  
 3rd Qu.: 748.0   3rd Qu.: 1.0000   3rd Qu.: 7.00   3rd Qu.:  6.000  
 Max.   :1000.0   Max.   :14.0000   Max.   :28.00   Max.   : 26.000
 
 
### Assessing author effort

Often authors will use more words when they are more passionate. For example, a mad airline passenger will leave a longer review the worse (the perceived) service. Conversely a less impassioned passenger may not feel compelled to spend a lot of time writing a review. Lengthy reviews may inflate overall sentiment since the reviews will inherently contain more positive or negative language as the review lengthens. This coding exercise helps to examine effort and sentiment.

In this exercise you will visualize the relationship between effort and sentiment. Recall your rental review tibble contains an id and that a word is represented in each row. As a result a simple count() of the id will capture the number of words used in each review. Then you will join this summary to the positive and negative data. Ultimately you will create a scatter plot that will visualize author review length and its relationship to polarity.

INSTRUCTIONS
100XP
INSTRUCTIONS
100XP
tidy_reviews and pos_neg from the previous exercises are available in your workspace.

Create effort using tidy_reviews and piping %>% the object to count(). Within count() pass in the vector id.
Perform an inner_join() using pos_neg and effort. Call the object pos_neg_with_effort.
Review pos_neg_with_effort.
Create pos_neg_pol by passing pos_neg_with_effort to mutate(). Define pol with an ifelse() function. This function will label items as "Positive" if polarity >= 0 else it will label them as "Negative".
Construct a visual with aes as polarity, n, color = pol. After the example code layer containing geom_point(alpha = 0.25) add another layer using geom_smooth to aid you in seeing the pattern.
 
 
 
 
 
 
 ```{r}
# Review tidy_reviews
tidy_reviews

# Review pos_neg
pos_neg

# Create effort
effort <- tidy_reviews %>% count(id)

# Inner join
pos_neg_with_effort <- inner_join(pos_neg, effort) 

# Review 
pos_neg_with_effort

# Add pol
pos_neg_pol <- pos_neg_with_effort %>%
  mutate(
    pol = ifelse(
      polarity >= 0, 
      "Positive", 
      "Negative"
    )
  )

# Plot
ggplot(
  pos_neg_pol, 
  aes(polarity, n, color = pol)
) + 
  geom_point(alpha = 0.25) +
  geom_smooth(method = "lm", se = FALSE) +
  theme_gdocs() +
  ggtitle("Relationship between word effort & polarity")

```

[resulted plot]("download (13).png")

### Comparison Cloud

This exercise will create a common visual for you to understand term frequency. Specifically, you will review the most frequent terms from among the positive and negative collapsed documents. Recall the TermDocumentMatrix all_tdm you created earlier. Instead of 1000 rental reviews the matrix contains 2 documents containing all reviews separated by the polarity() score.

It's usually easier to change the TDM to a matrix. From there you simply rename the columns. Remember that the colnames() function is called on the left side of the assignment operator as shown below.

colnames(OBJECT) <- c("COLUMN_NAME1", "COLUMN_NAME2")
Once done, you will reorder the matrix to see the most positive and negative words. Review these terms so you can answer the conclusion exercises!

Lastly, you'll visualize the terms using comparison.cloud().

INSTRUCTIONS
100XP
INSTRUCTIONS
100XP
Change the pre-loaded all_tdm to a matrix called all_tdm_m using as.matrix().
Use colnames() on all_tdm_m to declare c("positive", "negative").
Apply order() to all_tdm_m[,1] and set decreasing = TRUE.
Review the top 10 terms of the reordered TDM using pipe (%>%) then head() with n = 10.
Repeat the previous two steps with negative comments. Now you will order() by the second column, all_tdm_m[,2] and use decreasing = TRUE.
Review the 10 most negative terms indexing all_tdm_m by order_by_neg. Pipe this to head() with n = 10.
Call comparison.cloud() on all_tdm_m. Specify max.words equal to 20 and colors equal to "darkgreen" and "darkred".


```{r}
# Matrix
all_tdm_m <- as.matrix(all_tdm)

# Column names
colnames(all_tdm_m) <- c("positive", "negative")

# Top pos words
order_by_pos <- order(all_tdm_m[, 1], decreasing = TRUE)

# Review top 10 pos words
all_tdm_m[order_by_pos, ] %>% head(10)

# Top neg words
order_by_neg <- order(all_tdm_m[, 2], decreasing = TRUE)

# Review top 10 neg words
all_tdm_m[order_by_neg, ] %>% head(10)

# Comparison cloud
comparison.cloud(
  all_tdm_m, 
  max.words = 20, 
  colors = c("darkgreen", "darkred")
)

```

[resulted plot]("download (14).png")


### Scaled Comparison Cloud

Recall the "grade inflation" of polarity scores on the rental reviews? Sometimes, another way to uncover an insight is to scale the scores back to 0 then perform the corpus subset. This means some of the previously positive comments may become part of the negative subsection or vice versa since the mean is changed to 0. This exercise will help you scale the scores and then re-plot the comparison.cloud(). Removing the "grade inflation" can help provide additional insights.

Previously you applied polarity() to the bos_reviews$comments and created a comparison.cloud(). In this exercise you will scale() the outcome before creating the comparison.cloud(). See if this shows something different in the visual!

Since this is largely a review exercise, a lot of the code exists, just fill in the correct objects and parameters!

INSTRUCTIONS
100XP
INSTRUCTIONS
100XP
Review a section of the pre-loaded bos_pol$all while indexing [1:6,1:3].
Add a new column to called scaled_polarity with scale() applied to the polarity score column bos_pol$all$polarity.
For positive comments, subset() where the new column bos_reviews$scaled_polarity is greater than (>) zero.
For negative comments, subset() where the new column bos_reviews$scaled_polarity is less than (<) zero.
Create pos_terms using paste() on pos_comments.
Now create neg_terms with paste() on neg_comments.
Organize the collapsed documents, pos_terms and neg_terms documents into a single corpus called all_terms.
Following the usual tm workflow by nesting VectorSource() inside VCorpus() applied to all_terms.
Make the TermDocumentMatrix() using the all_corpus object. Note this is a TfIdf weighted TDM with basic cleaning functions.
Change all_tdm to all_tdm_m using as.matrix(). Then rename the columns in the existing code to "positive" and "negative".
Finally! apply comparison.cloud() to the matrix object all_tdm_m. Take notice of the new most frequent negative words. Maybe it will uncover an unknown insight!



```{r}
# Review
bos_pol$all[1:6,1:3]

# Scale/center & append
bos_reviews$scaled_polarity <- scale(bos_pol$all$polarity)

# Subset positive comments
pos_comments <- subset(bos_reviews$comments, bos_reviews$scaled_polarity > 0)

# Subset negative comments
neg_comments <- subset(bos_reviews$comments, bos_reviews$scaled_polarity < 0)

# Paste and collapse the positive comments
pos_terms <- paste(pos_comments, collapse = " ")

# Paste and collapse the negative comments
neg_terms <- paste(neg_comments, collapse = " ")

# Organize
all_terms <- c(pos_terms,neg_terms)

# VCorpus
all_corpus <- VCorpus(VectorSource(all_terms))

# TDM
all_tdm <- TermDocumentMatrix(
  all_corpus, 
  control = list(
    weighting = weightTfIdf,
    removePunctuation = TRUE, 
    stopwords = stopwords(kind = "en")
  )
)

# Column names
all_tdm_m <- as.matrix(all_tdm)
colnames(all_tdm_m) <- c("positive", "negative")

# Comparison cloud
comparison.cloud(
  all_tdm_m, 
  max.words = 100,
  colors = c("darkgreen", "darkred")
)
```


[resulted plot]("download (15).png")



